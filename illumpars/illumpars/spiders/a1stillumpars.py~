import scrapy
import csv
from scrapy import signals

class A1stillumparsSpider(scrapy.Spider):
    name = "A1stillumpars"
    allowed_domains = ["divan.ru"]
    start_urls = ["https://www.divan.ru/samara/category/potolocnye-svetilniki"]

    @classmethod
    def from_crawler(cls, crawler, *args, **kwargs):
        spider = super(A1stillumparsSpider, cls).from_crawler(crawler, *args, **kwargs)
        crawler.signals.connect(spider.open_spider, signals.spider_opened)
        crawler.signals.connect(spider.close_spider, signals.spider_closed)
        return spider

    def open_spider(self, spider):
        print("Открытие CSV файла...")
        self.file = open('illuminations.csv', mode='w', newline='', encoding='utf-8-sig')
        self.writer = csv.writer(self.file)
        self.writer.writerow(['name', 'price', 'url'])
        print("Файл открыт и заголовки записаны.")

    def parse(self, response):
        illuminations = response.css('div._Ud0k')
        for illum in illuminations:
            name = illum.css('div.lsooF span::text').get()
            price = illum.css('div.pY3d2 span::text').get()
            url = response.urljoin(illum.css('a::attr(href)').get())

            # Запись данных в CSV
            if self.writer:
                print(f"Запись в CSV: {name}, {price}, {url}")
                self.writer.writerow([name, price, url])

            yield {
                'name': name,
                'price': price,
                'url': url
            }

    def close_spider(self, spider):
        if self.file:
            print("Закрытие CSV файла...")
            self.file.close()
            print("Файл закрыт.")
